{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and Inverted Index w/h NLTK\n",
    "##### By Ruben Seoane, all credit to nlpforhackers.io\n",
    "Based on: http://nlpforhackers.io/building-a-simple-inverted-index-using-nltk/\n",
    "\n",
    "An Inverted Index is in _index data structure_ that stores a mapping from content, such as words or numbers, to its location in a database file, document or set of documents. It allows for **fast full text searches**, and it's used extensively in search engines.\n",
    "\n",
    "While building it, we will perform the following tasks:\n",
    "1. Using a stemmer from NLTK\n",
    "2. Filter words through a stopwords list\n",
    "3. Tokenize text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import defaultdict\n",
    "from nltk.stem.snowball import EnglishStemmer as ES\n",
    "\n",
    "class Index:\n",
    "    \"\"\"Inverted Index data structure\"\"\"\n",
    "    def __init__(self, tokenizer, stemmer=None, stopwords=None):\n",
    "        \"\"\"\n",
    "        tokenizer --NLTK compatile tokenizer function\n",
    "        stemmer   --NLTK compatible stemmer\n",
    "        stopwords --list of inored words\n",
    "        \"\"\"\n",
    "        self.tokenizer = tokenizer\n",
    "        self.stemmer = stemmer\n",
    "        self.index = defaultdict(list)\n",
    "        self.documents = {}\n",
    "        self.__unique_id = 0\n",
    "        if not stopwords:\n",
    "            self.stopwords = set()\n",
    "        else:\n",
    "            self.stopwords = set(stopwords)\n",
    "    \n",
    "    def lookup(self, word):\n",
    "        \"\"\"\n",
    "        Lookup a word in the index\n",
    "        \"\"\"\n",
    "        word = word.lower()\n",
    "        if self.stemmer:\n",
    "            word = self.stemmer.stem(word)\n",
    "            \n",
    "        return [self.documents.get(id, None) for id in self.index.get(word)]\n",
    "    \n",
    "    def add(self, document):\n",
    "        \"\"\"\n",
    "        Add a document string to the index\n",
    "        \"\"\"\n",
    "        for token in [t.lower() for t in nltk.word_tokenize(document)]:\n",
    "            if token in self.stopwords:\n",
    "                continue\n",
    "            \n",
    "            if self.stemmer:\n",
    "                token = self.stemmer.stem(token)\n",
    "                \n",
    "            if self.__unique_id not in self.index[token]:\n",
    "                self.index[token].append(self.__unique_id)\n",
    "                \n",
    "        self.documents[self.__unique_id] = document\n",
    "        self.__unique_id += 1\n",
    "        \n",
    "index = Index(nltk.word_tokenize,\n",
    "             ES(),nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stopwords** are used so that the index doesnt crate an enrtry for every word in the English language, as the words in such lists have no semantic meaning (so, that, the..)\n",
    "The **stemmer** is used to get a common for fro different inflections of the base word. Stemmers are heuristic approaches for determining the base form of a word fast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add some data and do some queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TOP10 Dire Straits\n",
    "index.add('Industrial Disease')\n",
    "index.add('Private Investigations')\n",
    "index.add('So Far Away')\n",
    "index.add('Twisting by the Pool')\n",
    "index.add('Skateaway')\n",
    "index.add('Walk of Life')\n",
    "index.add('Romeo and Juliet')\n",
    "index.add('Tunnel of Love')\n",
    "index.add('Money for Nothing')\n",
    "index.add('Sultans of Swing')\n",
    "\n",
    "# TOP10 Led Zeppelin\n",
    "index.add('Stairway To Heaven')\n",
    "index.add('Kashmir')\n",
    "index.add('Achilles Last Stand')\n",
    "index.add('Whole Lotta Love')\n",
    "index.add('Immigrant Song')\n",
    "index.add('Black Dog')\n",
    "index.add('When The Levee Breaks')\n",
    "index.add('Since I\\'ve Been Lovin\\' You')\n",
    "index.add('Since I\\'ve Been Loving You')\n",
    "index.add('Over the Hills and Far Away')\n",
    "index.add('Dazed and Confused') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tunnel of Love', 'Whole Lotta Love', \"Since I've Been Loving You\", 'Tunnel of Love', 'Whole Lotta Love', \"Since I've Been Loving You\"]\n"
     ]
    }
   ],
   "source": [
    "# Querying:\n",
    "print(index.lookup('loves'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tunnel of Love', 'Whole Lotta Love', \"Since I've Been Loving You\", 'Tunnel of Love', 'Whole Lotta Love', \"Since I've Been Loving You\"]\n"
     ]
    }
   ],
   "source": [
    "print(index.lookup('loved'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dazed and Confused', 'Dazed and Confused']\n"
     ]
    }
   ],
   "source": [
    "print(index.lookup('daze'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dazed and Confused', 'Dazed and Confused']\n"
     ]
    }
   ],
   "source": [
    "print(index.lookup('confusion'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if we pass inflected forms of the index (variations of the words that appear on it) we still get the correct results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
