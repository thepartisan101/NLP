{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Processing Raw Text\n",
    "##### By Ruben Seoane, adaptation of Chapter 3 from http://www.nltk.org/book_1ed/\n",
    "_\"Please note that the original link and book are using the urllib library methods, where this notebook is using Python 3.6.4, where **urllib3** is neccessary, thus, I've changed methods like urlopen(), read.decode() and others to the ones used by urllib3, documentation can be found here:http://urllib3.readthedocs.io/en/latest/user-guide.html. Project Gutenberg has slightly changed their link structure, so I updated it here \"_\n",
    "\n",
    "### Objectives:\n",
    "1. Write programs to access local and web files.\n",
    "2. Split documents into individual words and punctuation simbols for further analysis.\n",
    "3. Write programs to produce formated output and export to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## All exercises require the following code to start:\n",
    "import nltk, re, pprint\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Accessing Text from Web and a Local Disk\n",
    "#### Electronic Books\n",
    "We'll operate by accessing the free library from _Project Gutenberg_.\n",
    "In this case we choose document #2554, an English translation of _Crime and Punishment_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib3\n",
    "from urllib3 import request\n",
    "http = urllib3.PoolManager()\n",
    "url = \"http://www.gutenberg.org/files/2554/2554-0.txt\"\n",
    "response = http.request('GET',url)\n",
    "raw = response.data.decode('utf8')\n",
    "type(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1176965"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffThe Project Gutenberg EBook of Crime and Punishment, by Fyodor Dostoevsky\\r'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[:75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizing: Breaking up the string into a list of words and punctuation signs:\n",
    "tokens = word_tokenize(raw)\n",
    "type(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257726"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffThe',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'Crime',\n",
       " 'and',\n",
       " 'Punishment',\n",
       " ',',\n",
       " 'by']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.text.Text"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's crete an NLTK object to store our tokenized text so we can perform further processing\n",
    "text = nltk.Text(tokens)\n",
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['an',\n",
       " 'exceptionally',\n",
       " 'hot',\n",
       " 'evening',\n",
       " 'early',\n",
       " 'in',\n",
       " 'July',\n",
       " 'a',\n",
       " 'young',\n",
       " 'man',\n",
       " 'came',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'garret',\n",
       " 'in',\n",
       " 'which',\n",
       " 'he',\n",
       " 'lodged',\n",
       " 'in',\n",
       " 'S.',\n",
       " 'Place',\n",
       " 'and',\n",
       " 'walked',\n",
       " 'slowly',\n",
       " ',',\n",
       " 'as',\n",
       " 'though',\n",
       " 'in',\n",
       " 'hesitation',\n",
       " ',',\n",
       " 'towards',\n",
       " 'K.',\n",
       " 'bridge',\n",
       " '.',\n",
       " 'He',\n",
       " 'had',\n",
       " 'successfully']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[1024:1062]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Katerina Ivanovna; Pyotr Petrovitch; Pulcheria Alexandrovna; Avdotya\n",
      "Romanovna; Rodion Romanovitch; Marfa Petrovna; Sofya Semyonovna; old\n",
      "woman; Project Gutenberg-tm; Porfiry Petrovitch; Amalia Ivanovna;\n",
      "great deal; young man; Nikodim Fomitch; Ilya Petrovitch; Project\n",
      "Gutenberg; Andrey Semyonovitch; Hay Market; Dmitri Prokofitch; Good\n",
      "heavens\n"
     ]
    }
   ],
   "source": [
    "# Collocations are expressions of multiple words which commonly co-occur.\n",
    "text.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Project Gutenberg_ appears as a collocation. Each text obtained from the project contains a header with the name of the text, author, names of people who scanned the document, worked on the license, etc. In order to correctly detect where the content begins and ends, we inspect it manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5336"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.find('PART I')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1157810"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.rfind(\"End of Project Gutenberg’s Crime and Punishment, by Fyodor Dostoevsky\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's delimit the text to the found positions:\n",
    "## rfind() is for \"reverse find\"\n",
    "raw = raw[5336:1157810]\n",
    "raw.find(\"PART I\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dealing with HTML\n",
    "We'll pick a BBC News story called _Blondes to die out in 200 years_, an urban legend passed along by the BBC as established scientific fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!doctype html public \"-//W3C//DTD HTML 4.0 Transitional//EN'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://news.bbc.co.uk/2/hi/health/2284783.stm\"\n",
    "r = http.request('GET',url)\n",
    "html = r.data.decode('utf8')\n",
    "html[:60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to see all HTML content we can use _**print(html)**_. But to extract the article's text out of it, we will employ the _**BeatifulSoup**_ library, which can be installed, in its last version as **pip install bs4**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file c:\\python36\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['BBC',\n",
       " 'NEWS',\n",
       " '|',\n",
       " 'Health',\n",
       " '|',\n",
       " 'Blondes',\n",
       " \"'to\",\n",
       " 'die',\n",
       " 'out',\n",
       " 'in',\n",
       " '200',\n",
       " \"years'\",\n",
       " 'NEWS',\n",
       " 'SPORT',\n",
       " 'WEATHER',\n",
       " 'WORLD',\n",
       " 'SERVICE',\n",
       " 'A-Z',\n",
       " 'INDEX',\n",
       " 'SEARCH',\n",
       " 'You',\n",
       " 'are',\n",
       " 'in',\n",
       " ':',\n",
       " 'Health',\n",
       " 'News',\n",
       " 'Front',\n",
       " 'Page',\n",
       " 'Africa',\n",
       " 'Americas',\n",
       " 'Asia-Pacific',\n",
       " 'Europe',\n",
       " 'Middle',\n",
       " 'East',\n",
       " 'South',\n",
       " 'Asia',\n",
       " 'UK',\n",
       " 'Business',\n",
       " 'Entertainment',\n",
       " 'Science/Nature',\n",
       " 'Technology',\n",
       " 'Health',\n",
       " 'Medical',\n",
       " 'notes',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '-',\n",
       " 'Talking',\n",
       " 'Point',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '-',\n",
       " 'Country',\n",
       " 'Profiles',\n",
       " 'In',\n",
       " 'Depth',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '-',\n",
       " 'Programmes',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '-',\n",
       " 'SERVICES',\n",
       " 'Daily',\n",
       " 'E-mail',\n",
       " 'News',\n",
       " 'Ticker',\n",
       " 'Mobile/PDAs',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '-',\n",
       " 'Text',\n",
       " 'Only',\n",
       " 'Feedback',\n",
       " 'Help',\n",
       " 'EDITIONS',\n",
       " 'Change',\n",
       " 'to',\n",
       " 'UK',\n",
       " 'Friday',\n",
       " ',',\n",
       " '27',\n",
       " 'September',\n",
       " ',',\n",
       " '2002',\n",
       " ',',\n",
       " '11:51',\n",
       " 'GMT',\n",
       " '12:51',\n",
       " 'UK',\n",
       " 'Blondes',\n",
       " \"'to\",\n",
       " 'die',\n",
       " 'out',\n",
       " 'in',\n",
       " '200',\n",
       " \"years'\",\n",
       " 'Scientists',\n",
       " 'believe',\n",
       " 'the',\n",
       " 'last',\n",
       " 'blondes',\n",
       " 'will',\n",
       " 'be',\n",
       " 'in',\n",
       " 'Finland',\n",
       " 'The',\n",
       " 'last',\n",
       " 'natural',\n",
       " 'blondes',\n",
       " 'will',\n",
       " 'die',\n",
       " 'out',\n",
       " 'within',\n",
       " '200',\n",
       " 'years',\n",
       " ',',\n",
       " 'scientists',\n",
       " 'believe',\n",
       " '.',\n",
       " 'A',\n",
       " 'study',\n",
       " 'by',\n",
       " 'experts',\n",
       " 'in',\n",
       " 'Germany',\n",
       " 'suggests',\n",
       " 'people',\n",
       " 'with',\n",
       " 'blonde',\n",
       " 'hair',\n",
       " 'are',\n",
       " 'an',\n",
       " 'endangered',\n",
       " 'species',\n",
       " 'and',\n",
       " 'will',\n",
       " 'become',\n",
       " 'extinct',\n",
       " 'by',\n",
       " '2202',\n",
       " '.',\n",
       " 'Researchers',\n",
       " 'predict',\n",
       " 'the',\n",
       " 'last',\n",
       " 'truly',\n",
       " 'natural',\n",
       " 'blonde',\n",
       " 'will',\n",
       " 'be',\n",
       " 'born',\n",
       " 'in',\n",
       " 'Finland',\n",
       " '-',\n",
       " 'the',\n",
       " 'country',\n",
       " 'with',\n",
       " 'the',\n",
       " 'highest',\n",
       " 'proportion',\n",
       " 'of',\n",
       " 'blondes',\n",
       " '.',\n",
       " 'The',\n",
       " 'frequency',\n",
       " 'of',\n",
       " 'blondes',\n",
       " 'may',\n",
       " 'drop',\n",
       " 'but',\n",
       " 'they',\n",
       " 'wo',\n",
       " \"n't\",\n",
       " 'disappear',\n",
       " 'Prof',\n",
       " 'Jonathan',\n",
       " 'Rees',\n",
       " ',',\n",
       " 'University',\n",
       " 'of',\n",
       " 'Edinburgh',\n",
       " 'But',\n",
       " 'they',\n",
       " 'say',\n",
       " 'too',\n",
       " 'few',\n",
       " 'people',\n",
       " 'now',\n",
       " 'carry',\n",
       " 'the',\n",
       " 'gene',\n",
       " 'for',\n",
       " 'blondes',\n",
       " 'to',\n",
       " 'last',\n",
       " 'beyond',\n",
       " 'the',\n",
       " 'next',\n",
       " 'two',\n",
       " 'centuries',\n",
       " '.',\n",
       " 'The',\n",
       " 'problem',\n",
       " 'is',\n",
       " 'that',\n",
       " 'blonde',\n",
       " 'hair',\n",
       " 'is',\n",
       " 'caused',\n",
       " 'by',\n",
       " 'a',\n",
       " 'recessive',\n",
       " 'gene',\n",
       " '.',\n",
       " 'In',\n",
       " 'order',\n",
       " 'for',\n",
       " 'a',\n",
       " 'child',\n",
       " 'to',\n",
       " 'have',\n",
       " 'blonde',\n",
       " 'hair',\n",
       " ',',\n",
       " 'it',\n",
       " 'must',\n",
       " 'have',\n",
       " 'the',\n",
       " 'gene',\n",
       " 'on',\n",
       " 'both',\n",
       " 'sides',\n",
       " 'of',\n",
       " 'the',\n",
       " 'family',\n",
       " 'in',\n",
       " 'the',\n",
       " 'grandparents',\n",
       " \"'\",\n",
       " 'generation',\n",
       " '.',\n",
       " 'Dyed',\n",
       " 'rivals',\n",
       " 'The',\n",
       " 'researchers',\n",
       " 'also',\n",
       " 'believe',\n",
       " 'that',\n",
       " 'so-called',\n",
       " 'bottle',\n",
       " 'blondes',\n",
       " 'may',\n",
       " 'be',\n",
       " 'to',\n",
       " 'blame',\n",
       " 'for',\n",
       " 'the',\n",
       " 'demise',\n",
       " 'of',\n",
       " 'their',\n",
       " 'natural',\n",
       " 'rivals',\n",
       " '.',\n",
       " 'They',\n",
       " 'suggest',\n",
       " 'that',\n",
       " 'dyed-blondes',\n",
       " 'are',\n",
       " 'more',\n",
       " 'attractive',\n",
       " 'to',\n",
       " 'men',\n",
       " 'who',\n",
       " 'choose',\n",
       " 'them',\n",
       " 'as',\n",
       " 'partners',\n",
       " 'over',\n",
       " 'true',\n",
       " 'blondes',\n",
       " '.',\n",
       " 'Bottle-blondes',\n",
       " 'like',\n",
       " 'Ann',\n",
       " 'Widdecombe',\n",
       " 'may',\n",
       " 'be',\n",
       " 'to',\n",
       " 'blame',\n",
       " 'But',\n",
       " 'Jonathan',\n",
       " 'Rees',\n",
       " ',',\n",
       " 'professor',\n",
       " 'of',\n",
       " 'dermatology',\n",
       " 'at',\n",
       " 'the',\n",
       " 'University',\n",
       " 'of',\n",
       " 'Edinburgh',\n",
       " 'said',\n",
       " 'it',\n",
       " 'was',\n",
       " 'unlikely',\n",
       " 'blondes',\n",
       " 'would',\n",
       " 'die',\n",
       " 'out',\n",
       " 'completely',\n",
       " '.',\n",
       " '``',\n",
       " 'Genes',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'die',\n",
       " 'out',\n",
       " 'unless',\n",
       " 'there',\n",
       " 'is',\n",
       " 'a',\n",
       " 'disadvantage',\n",
       " 'of',\n",
       " 'having',\n",
       " 'that',\n",
       " 'gene',\n",
       " 'or',\n",
       " 'by',\n",
       " 'chance',\n",
       " '.',\n",
       " 'They',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'disappear',\n",
       " ',',\n",
       " \"''\",\n",
       " 'he',\n",
       " 'told',\n",
       " 'BBC',\n",
       " 'News',\n",
       " 'Online',\n",
       " '.',\n",
       " '``',\n",
       " 'The',\n",
       " 'only',\n",
       " 'reason',\n",
       " 'blondes',\n",
       " 'would',\n",
       " 'disappear',\n",
       " 'is',\n",
       " 'if',\n",
       " 'having',\n",
       " 'the',\n",
       " 'gene',\n",
       " 'was',\n",
       " 'a',\n",
       " 'disadvantage',\n",
       " 'and',\n",
       " 'I',\n",
       " 'do',\n",
       " 'not',\n",
       " 'think',\n",
       " 'that',\n",
       " 'is',\n",
       " 'the',\n",
       " 'case',\n",
       " '.',\n",
       " '``',\n",
       " 'The',\n",
       " 'frequency',\n",
       " 'of',\n",
       " 'blondes',\n",
       " 'may',\n",
       " 'drop',\n",
       " 'but',\n",
       " 'they',\n",
       " 'wo',\n",
       " \"n't\",\n",
       " 'disappear',\n",
       " '.',\n",
       " \"''\",\n",
       " 'See',\n",
       " 'also',\n",
       " ':',\n",
       " '28',\n",
       " 'Mar',\n",
       " '01',\n",
       " '|',\n",
       " 'Education',\n",
       " 'What',\n",
       " 'is',\n",
       " 'it',\n",
       " 'about',\n",
       " 'blondes',\n",
       " '?',\n",
       " '09',\n",
       " 'Apr',\n",
       " '99',\n",
       " '|',\n",
       " 'Health',\n",
       " 'Platinum',\n",
       " 'blondes',\n",
       " 'are',\n",
       " 'labelled',\n",
       " 'as',\n",
       " 'dumb',\n",
       " '17',\n",
       " 'Apr',\n",
       " '02',\n",
       " '|',\n",
       " 'Health',\n",
       " 'Hair',\n",
       " 'dye',\n",
       " 'cancer',\n",
       " 'alert',\n",
       " 'Internet',\n",
       " 'links',\n",
       " ':',\n",
       " 'University',\n",
       " 'of',\n",
       " 'Edinburgh',\n",
       " 'The',\n",
       " 'BBC',\n",
       " 'is',\n",
       " 'not',\n",
       " 'responsible',\n",
       " 'for',\n",
       " 'the',\n",
       " 'content',\n",
       " 'of',\n",
       " 'external',\n",
       " 'internet',\n",
       " 'sites',\n",
       " 'Top',\n",
       " 'Health',\n",
       " 'stories',\n",
       " 'now',\n",
       " ':',\n",
       " 'Heart',\n",
       " 'risk',\n",
       " 'link',\n",
       " 'to',\n",
       " 'big',\n",
       " 'families',\n",
       " 'Back',\n",
       " 'pain',\n",
       " 'drug',\n",
       " \"'may\",\n",
       " 'aid',\n",
       " \"diabetics'\",\n",
       " 'Congo',\n",
       " 'Ebola',\n",
       " 'outbreak',\n",
       " 'confirmed',\n",
       " 'Vegetables',\n",
       " 'ward',\n",
       " 'off',\n",
       " \"Alzheimer's\",\n",
       " 'Polio',\n",
       " 'campaign',\n",
       " 'launched',\n",
       " 'in',\n",
       " 'Iraq',\n",
       " 'Gene',\n",
       " 'defect',\n",
       " 'explains',\n",
       " 'high',\n",
       " 'blood',\n",
       " 'pressure',\n",
       " 'Botox',\n",
       " \"'may\",\n",
       " 'cause',\n",
       " 'new',\n",
       " \"wrinkles'\",\n",
       " 'Alien',\n",
       " \"'abductees\",\n",
       " \"'\",\n",
       " 'show',\n",
       " 'real',\n",
       " 'symptoms',\n",
       " 'Links',\n",
       " 'to',\n",
       " 'more',\n",
       " 'Health',\n",
       " 'stories',\n",
       " 'are',\n",
       " 'at',\n",
       " 'the',\n",
       " 'foot',\n",
       " 'of',\n",
       " 'the',\n",
       " 'page',\n",
       " '.',\n",
       " 'E-mail',\n",
       " 'this',\n",
       " 'story',\n",
       " 'to',\n",
       " 'a',\n",
       " 'friend',\n",
       " 'Links',\n",
       " 'to',\n",
       " 'more',\n",
       " 'Health',\n",
       " 'stories',\n",
       " 'In',\n",
       " 'This',\n",
       " 'Section',\n",
       " 'Heart',\n",
       " 'risk',\n",
       " 'link',\n",
       " 'to',\n",
       " 'big',\n",
       " 'families',\n",
       " 'Back',\n",
       " 'pain',\n",
       " 'drug',\n",
       " \"'may\",\n",
       " 'aid',\n",
       " \"diabetics'\",\n",
       " 'Congo',\n",
       " 'Ebola',\n",
       " 'outbreak',\n",
       " 'confirmed',\n",
       " 'Vegetables',\n",
       " 'ward',\n",
       " 'off',\n",
       " \"Alzheimer's\",\n",
       " 'Polio',\n",
       " 'campaign',\n",
       " 'launched',\n",
       " 'in',\n",
       " 'Iraq',\n",
       " 'Gene',\n",
       " 'defect',\n",
       " 'explains',\n",
       " 'high',\n",
       " 'blood',\n",
       " 'pressure',\n",
       " 'Botox',\n",
       " \"'may\",\n",
       " 'cause',\n",
       " 'new',\n",
       " \"wrinkles'\",\n",
       " 'Alien',\n",
       " \"'abductees\",\n",
       " \"'\",\n",
       " 'show',\n",
       " 'real',\n",
       " 'symptoms',\n",
       " 'How',\n",
       " 'sperm',\n",
       " 'wriggle',\n",
       " 'Bollywood',\n",
       " 'told',\n",
       " 'to',\n",
       " 'stub',\n",
       " 'it',\n",
       " 'out',\n",
       " 'Fears',\n",
       " 'over',\n",
       " 'tuna',\n",
       " 'health',\n",
       " 'risk',\n",
       " 'to',\n",
       " 'babies',\n",
       " 'Public',\n",
       " 'can',\n",
       " 'be',\n",
       " 'taught',\n",
       " 'to',\n",
       " 'spot',\n",
       " 'strokes',\n",
       " '^^',\n",
       " 'Back',\n",
       " 'to',\n",
       " 'top',\n",
       " 'News',\n",
       " 'Front',\n",
       " 'Page',\n",
       " '|',\n",
       " 'Africa',\n",
       " '|',\n",
       " 'Americas',\n",
       " '|',\n",
       " 'Asia-Pacific',\n",
       " '|',\n",
       " 'Europe',\n",
       " '|',\n",
       " 'Middle',\n",
       " 'East',\n",
       " '|',\n",
       " 'South',\n",
       " 'Asia',\n",
       " '|',\n",
       " 'UK',\n",
       " '|',\n",
       " 'Business',\n",
       " '|',\n",
       " 'Entertainment',\n",
       " '|',\n",
       " 'Science/Nature',\n",
       " '|',\n",
       " 'Technology',\n",
       " '|',\n",
       " 'Health',\n",
       " '|',\n",
       " 'Talking',\n",
       " 'Point',\n",
       " '|',\n",
       " 'Country',\n",
       " 'Profiles',\n",
       " '|',\n",
       " 'In',\n",
       " 'Depth',\n",
       " '|',\n",
       " 'Programmes',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " 'To',\n",
       " 'BBC',\n",
       " 'Sport',\n",
       " '>',\n",
       " '>',\n",
       " '|',\n",
       " 'To',\n",
       " 'BBC',\n",
       " 'Weather',\n",
       " '>',\n",
       " '>',\n",
       " '|',\n",
       " 'To',\n",
       " 'BBC',\n",
       " 'World',\n",
       " 'Service',\n",
       " '>',\n",
       " '>',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '©',\n",
       " 'MMIII',\n",
       " '|',\n",
       " 'News',\n",
       " 'Sources',\n",
       " '|',\n",
       " 'Privacy',\n",
       " '<',\n",
       " '!',\n",
       " '--',\n",
       " 'var',\n",
       " 'pCid=',\n",
       " \"''\",\n",
       " 'uk_bbc_0',\n",
       " \"''\",\n",
       " ';',\n",
       " 'var',\n",
       " 'w0=1',\n",
       " ';',\n",
       " 'var',\n",
       " 'refR=escape',\n",
       " '(',\n",
       " 'document.referrer',\n",
       " ')',\n",
       " ';',\n",
       " 'if',\n",
       " '(',\n",
       " 'refR.length',\n",
       " '>',\n",
       " '=252',\n",
       " ')',\n",
       " 'refR=refR.substring',\n",
       " '(',\n",
       " '0,252',\n",
       " ')',\n",
       " '+',\n",
       " \"''\",\n",
       " '...',\n",
       " \"''\",\n",
       " ';',\n",
       " '//',\n",
       " '--',\n",
       " '>',\n",
       " '<',\n",
       " '!',\n",
       " '--',\n",
       " 'var',\n",
       " 'w0=0',\n",
       " ';',\n",
       " '//',\n",
       " '--',\n",
       " '>',\n",
       " '<',\n",
       " '!',\n",
       " '--',\n",
       " 'if',\n",
       " '(',\n",
       " 'w0',\n",
       " ')',\n",
       " '{',\n",
       " 'var',\n",
       " 'imgN=',\n",
       " \"'\",\n",
       " '<',\n",
       " 'img',\n",
       " 'src=',\n",
       " \"''\",\n",
       " 'http',\n",
       " ':',\n",
       " '//server-uk.imrworldwide.com/cgi-bin/count',\n",
       " '?',\n",
       " \"ref='+\",\n",
       " 'refR+',\n",
       " \"'\",\n",
       " '&',\n",
       " \"cid='+pCid+\",\n",
       " \"'\",\n",
       " \"''\",\n",
       " 'width=1',\n",
       " 'height=1',\n",
       " '>',\n",
       " \"'\",\n",
       " ';',\n",
       " 'if',\n",
       " '(',\n",
       " 'navigator.userAgent.indexOf',\n",
       " '(',\n",
       " \"'Mac\",\n",
       " \"'\",\n",
       " ')',\n",
       " '!',\n",
       " '=-1',\n",
       " ')',\n",
       " '{',\n",
       " 'document.write',\n",
       " '(',\n",
       " 'imgN',\n",
       " ')',\n",
       " ';',\n",
       " '}',\n",
       " 'else',\n",
       " '{',\n",
       " 'document.write',\n",
       " '(',\n",
       " \"'\",\n",
       " '<',\n",
       " 'applet',\n",
       " 'code=',\n",
       " \"''\",\n",
       " 'Measure.class',\n",
       " \"''\",\n",
       " \"'+\",\n",
       " \"'codebase=\",\n",
       " \"''\",\n",
       " 'http',\n",
       " ':',\n",
       " '//server-uk.imrworldwide.com/',\n",
       " \"''\",\n",
       " \"'+'width=1\",\n",
       " 'height=2',\n",
       " '>',\n",
       " \"'+\",\n",
       " \"'\",\n",
       " '<',\n",
       " 'param',\n",
       " 'name=',\n",
       " \"''\",\n",
       " 'ref',\n",
       " \"''\",\n",
       " 'value=',\n",
       " \"''\",\n",
       " \"'+refR+\",\n",
       " \"'\",\n",
       " \"''\",\n",
       " '>',\n",
       " \"'+\",\n",
       " \"'\",\n",
       " '<',\n",
       " 'param',\n",
       " 'name=',\n",
       " \"''\",\n",
       " 'cid',\n",
       " \"''\",\n",
       " 'value=',\n",
       " \"''\",\n",
       " \"'+pCid+\",\n",
       " \"'\",\n",
       " \"''\",\n",
       " '>',\n",
       " '<',\n",
       " 'textflow',\n",
       " '>',\n",
       " \"'+imgN+\",\n",
       " \"'\",\n",
       " '<',\n",
       " '/textflow',\n",
       " '>',\n",
       " '<',\n",
       " '/applet',\n",
       " '>',\n",
       " \"'\",\n",
       " ')',\n",
       " ';',\n",
       " '}',\n",
       " '}',\n",
       " 'document.write',\n",
       " '(',\n",
       " '``',\n",
       " '<',\n",
       " 'COMMENT',\n",
       " '>',\n",
       " \"''\",\n",
       " ')',\n",
       " ';',\n",
       " '//',\n",
       " '--',\n",
       " '>',\n",
       " 'var',\n",
       " 'si',\n",
       " '=',\n",
       " 'document.location+',\n",
       " \"''\",\n",
       " \"''\",\n",
       " ';',\n",
       " 'var',\n",
       " 'tsi',\n",
       " '=',\n",
       " 'si.replace',\n",
       " '(',\n",
       " '``',\n",
       " '.stm',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " \"''\",\n",
       " ')',\n",
       " '.substr',\n",
       " '(',\n",
       " 'si.length-11',\n",
       " ',',\n",
       " 'si.length',\n",
       " ')',\n",
       " ';',\n",
       " 'if',\n",
       " '(',\n",
       " '!',\n",
       " 'tsi.match',\n",
       " '(',\n",
       " '/\\\\d\\\\d\\\\d\\\\d\\\\d\\\\d\\\\d/',\n",
       " ')',\n",
       " ')',\n",
       " '{',\n",
       " 'tsi',\n",
       " '=',\n",
       " '0',\n",
       " ';',\n",
       " '}',\n",
       " 'document.write',\n",
       " '(',\n",
       " \"'\",\n",
       " '<',\n",
       " 'img',\n",
       " 'src=',\n",
       " \"''\",\n",
       " 'http',\n",
       " ':',\n",
       " '//stats.bbc.co.uk/o.gif',\n",
       " '?',\n",
       " '~RS~s~RS~News~RS~t~RS~HighWeb_Legacy~RS~i~RS~',\n",
       " \"'\",\n",
       " '+',\n",
       " 'tsi',\n",
       " '+',\n",
       " \"'~RS~p~RS~0~RS~u~RS~/2/hi/health/2284783.stm~RS~r~RS~\",\n",
       " '(',\n",
       " 'none',\n",
       " ')',\n",
       " '~RS~a~RS~International~RS~q~RS~~RS~z~RS~14~RS~',\n",
       " \"''\",\n",
       " '>',\n",
       " \"'\",\n",
       " ')',\n",
       " ';']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "raw = BeautifulSoup(html).get_text()\n",
    "tokens = word_tokenize(raw)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output still contanins unwanted material belonging to site navigation menus and related stories, through trial and error you can find the start and end indexes for the content of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 5 of 5 matches:\n",
      "hey say too few people now carry the gene for blondes to last beyond the next \n",
      "blonde hair is caused by a recessive gene . In order for a child to have blond\n",
      " have blonde hair , it must have the gene on both sides of the family in the g\n",
      "ere is a disadvantage of having that gene or by chance . They do n't disappear\n",
      "des would disappear is if having the gene was a disadvantage and I do not thin\n"
     ]
    }
   ],
   "source": [
    "tokens = tokens[110:390]\n",
    "text = nltk.Text(tokens)\n",
    "text.concordance('gene')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Processing RSS Feeds\n",
    "We will use a Python library called _Universal Feed Parser_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language Log\n"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "blog = feedparser.parse(\"http://languagelog.ldc.upenn.edu/nll/?feed=atom\") \n",
    "print(blog['feed']['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(blog.entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Graphic antipairs'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post = blog.entries[2]\n",
    "post.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p>Currently on the internet in China, there is a flurry of discussion'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = post.content[0].value\n",
    "content[:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file c:\\python36\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Currently',\n",
       " 'on',\n",
       " 'the',\n",
       " 'internet',\n",
       " 'in',\n",
       " 'China',\n",
       " ',',\n",
       " 'there',\n",
       " 'is',\n",
       " 'a',\n",
       " 'flurry',\n",
       " 'of',\n",
       " 'discussion',\n",
       " 'on',\n",
       " 'characters',\n",
       " 'that',\n",
       " 'are',\n",
       " 'mirror',\n",
       " ',',\n",
       " 'flipped',\n",
       " ',',\n",
       " 'reversed',\n",
       " ',',\n",
       " 'or',\n",
       " 'inverted',\n",
       " 'images',\n",
       " 'of',\n",
       " 'each',\n",
       " 'other',\n",
       " '.',\n",
       " 'Here',\n",
       " 'are',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'examples',\n",
       " 'that',\n",
       " 'have',\n",
       " 'been',\n",
       " 'cited',\n",
       " '(',\n",
       " 'except',\n",
       " 'for',\n",
       " 'the',\n",
       " 'last',\n",
       " 'two',\n",
       " 'sets',\n",
       " ',',\n",
       " 'which',\n",
       " 'were',\n",
       " 'added',\n",
       " 'by',\n",
       " 'me',\n",
       " 'to',\n",
       " 'illustrate',\n",
       " 'other',\n",
       " 'types',\n",
       " 'of',\n",
       " 'minimal',\n",
       " 'differences',\n",
       " ')',\n",
       " ':',\n",
       " 'chǎng',\n",
       " '厂',\n",
       " '(',\n",
       " '``',\n",
       " 'factory',\n",
       " \"''\",\n",
       " ')',\n",
       " '||',\n",
       " 'yí',\n",
       " ',',\n",
       " 'jí',\n",
       " '乁',\n",
       " ',',\n",
       " 'ancient',\n",
       " 'form',\n",
       " 'of',\n",
       " 'yí',\n",
       " '移',\n",
       " '(',\n",
       " '``',\n",
       " 'move',\n",
       " ';',\n",
       " 'shift',\n",
       " \"''\",\n",
       " ')',\n",
       " 'or',\n",
       " 'jí',\n",
       " '及',\n",
       " '(',\n",
       " '``',\n",
       " 'and',\n",
       " ';',\n",
       " 'reach',\n",
       " 'to',\n",
       " \"''\",\n",
       " ')',\n",
       " '移',\n",
       " 'piàn',\n",
       " '片',\n",
       " '(',\n",
       " '``',\n",
       " 'sheet',\n",
       " ';',\n",
       " 'piece',\n",
       " ';',\n",
       " 'slice',\n",
       " \"''\",\n",
       " ')',\n",
       " '||',\n",
       " 'pán',\n",
       " '爿',\n",
       " '(',\n",
       " '``',\n",
       " 'half',\n",
       " 'of',\n",
       " 'a',\n",
       " 'tree',\n",
       " 'trunk',\n",
       " \"''\",\n",
       " ')',\n",
       " 'yù',\n",
       " '玉',\n",
       " '(',\n",
       " '``',\n",
       " 'jade',\n",
       " \"''\",\n",
       " ')',\n",
       " '||',\n",
       " 'sù',\n",
       " '玊',\n",
       " '(',\n",
       " '``',\n",
       " 'jade',\n",
       " 'with',\n",
       " 'a',\n",
       " 'blemish',\n",
       " ';',\n",
       " 'a',\n",
       " 'jade',\n",
       " 'worker',\n",
       " ';',\n",
       " 'a',\n",
       " 'surname',\n",
       " \"''\",\n",
       " ')',\n",
       " 'chì',\n",
       " '翅',\n",
       " '(',\n",
       " '``',\n",
       " 'wing',\n",
       " ';',\n",
       " 'fin',\n",
       " \"''\",\n",
       " ')',\n",
       " '||',\n",
       " 'chì',\n",
       " '翄',\n",
       " '(',\n",
       " '``',\n",
       " 'wing',\n",
       " ';',\n",
       " 'fin',\n",
       " \"''\",\n",
       " ')',\n",
       " ',',\n",
       " 'a',\n",
       " 'variant',\n",
       " 'of',\n",
       " 'chì',\n",
       " '翅',\n",
       " '(',\n",
       " '``',\n",
       " 'wing',\n",
       " ';',\n",
       " 'fin',\n",
       " \"''\",\n",
       " ')',\n",
       " '!',\n",
       " '!',\n",
       " 'chǎng',\n",
       " '昶',\n",
       " '(',\n",
       " '``',\n",
       " 'bright',\n",
       " ';',\n",
       " 'long',\n",
       " 'day',\n",
       " ';',\n",
       " 'expansive',\n",
       " ';',\n",
       " 'surname',\n",
       " \"''\",\n",
       " ')',\n",
       " '||',\n",
       " 'ǎi',\n",
       " '昹',\n",
       " '(',\n",
       " '``',\n",
       " 'name',\n",
       " 'of',\n",
       " 'a',\n",
       " 'star',\n",
       " \"''\",\n",
       " ')',\n",
       " 'zè',\n",
       " '仄',\n",
       " '(',\n",
       " '``',\n",
       " 'narrow',\n",
       " ';',\n",
       " 'oblique',\n",
       " 'tones',\n",
       " 'in',\n",
       " 'prosody',\n",
       " ';',\n",
       " 'a',\n",
       " 'feeling',\n",
       " 'of',\n",
       " 'unease',\n",
       " \"''\",\n",
       " ')',\n",
       " '||',\n",
       " 'wáng',\n",
       " '亾',\n",
       " '(',\n",
       " '``',\n",
       " 'death',\n",
       " ';',\n",
       " 'destroyed',\n",
       " ';',\n",
       " 'lost',\n",
       " 'perished',\n",
       " \"''\",\n",
       " ')',\n",
       " ',',\n",
       " 'an',\n",
       " 'early',\n",
       " 'variant',\n",
       " 'of',\n",
       " 'wáng',\n",
       " '亡',\n",
       " ';',\n",
       " 'another',\n",
       " 'early',\n",
       " 'variant',\n",
       " 'is',\n",
       " '兦',\n",
       " 'bì',\n",
       " '币',\n",
       " '(',\n",
       " '``',\n",
       " 'currency',\n",
       " ';',\n",
       " 'money',\n",
       " \"''\",\n",
       " ')',\n",
       " '||',\n",
       " 'zā',\n",
       " '帀',\n",
       " '(',\n",
       " '``',\n",
       " 'to',\n",
       " 'go',\n",
       " 'round',\n",
       " ';',\n",
       " 'to',\n",
       " 'make',\n",
       " 'a',\n",
       " 'circuit',\n",
       " ';',\n",
       " 'to',\n",
       " 'make',\n",
       " 'a',\n",
       " 'revolution',\n",
       " ';',\n",
       " 'to',\n",
       " 'turn',\n",
       " 'round',\n",
       " ';',\n",
       " 'encircle',\n",
       " \"''\",\n",
       " ')',\n",
       " ',',\n",
       " 'a',\n",
       " 'variant',\n",
       " 'of',\n",
       " '匝',\n",
       " 'yǔn',\n",
       " '陨',\n",
       " '(',\n",
       " '``',\n",
       " 'fall',\n",
       " 'from',\n",
       " 'the',\n",
       " 'sky',\n",
       " ';',\n",
       " 'falling',\n",
       " '/',\n",
       " 'shooting',\n",
       " 'star',\n",
       " \"''\",\n",
       " ')',\n",
       " '||',\n",
       " 'yún',\n",
       " '郧',\n",
       " '(',\n",
       " '``',\n",
       " 'name',\n",
       " 'of',\n",
       " 'an',\n",
       " 'ancient',\n",
       " 'kingdom',\n",
       " 'or',\n",
       " 'county',\n",
       " ';',\n",
       " 'surname',\n",
       " \"''\",\n",
       " ')',\n",
       " 'rén',\n",
       " '人',\n",
       " '(',\n",
       " '``',\n",
       " 'person',\n",
       " ';',\n",
       " 'human',\n",
       " \"''\",\n",
       " ')',\n",
       " '||',\n",
       " 'rù',\n",
       " '入',\n",
       " '(',\n",
       " '``',\n",
       " 'into',\n",
       " ';',\n",
       " 'enter',\n",
       " \"''\",\n",
       " ')',\n",
       " 'yǐ',\n",
       " '已',\n",
       " '(',\n",
       " '``',\n",
       " 'already',\n",
       " \"''\",\n",
       " ')',\n",
       " '||',\n",
       " 'jǐ',\n",
       " '己',\n",
       " '(',\n",
       " '``',\n",
       " 'self',\n",
       " \"''\",\n",
       " ')',\n",
       " '||',\n",
       " 'sì',\n",
       " '巳',\n",
       " '(',\n",
       " '``',\n",
       " 'the',\n",
       " 'hours',\n",
       " 'from',\n",
       " '9',\n",
       " 'to',\n",
       " '11',\n",
       " ';',\n",
       " '6th',\n",
       " 'terrestrial',\n",
       " 'branch',\n",
       " 'in',\n",
       " 'the',\n",
       " 'sexagenary',\n",
       " 'calendrical',\n",
       " 'cycle',\n",
       " 'Since',\n",
       " 'there',\n",
       " 'are',\n",
       " 'hundreds',\n",
       " ',',\n",
       " 'if',\n",
       " 'not',\n",
       " 'thousands',\n",
       " ',',\n",
       " 'of',\n",
       " 'such',\n",
       " 'graphic',\n",
       " 'minimal',\n",
       " 'pairs',\n",
       " 'that',\n",
       " 'differ',\n",
       " 'only',\n",
       " 'by',\n",
       " 'orientation',\n",
       " 'or',\n",
       " 'by',\n",
       " 'presence',\n",
       " ',',\n",
       " 'absence',\n",
       " ',',\n",
       " 'or',\n",
       " 'placement',\n",
       " 'of',\n",
       " 'a',\n",
       " 'single',\n",
       " 'tiny',\n",
       " 'feature',\n",
       " ',',\n",
       " 'one',\n",
       " 'can',\n",
       " 'get',\n",
       " 'a',\n",
       " 'sense',\n",
       " 'of',\n",
       " 'how',\n",
       " 'challenging',\n",
       " 'the',\n",
       " 'Chinese',\n",
       " 'script',\n",
       " 'must',\n",
       " 'be',\n",
       " 'for',\n",
       " 'dyslexics',\n",
       " '.',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'not',\n",
       " 'dyslexic',\n",
       " ',',\n",
       " 'but',\n",
       " 'I',\n",
       " 'find',\n",
       " 'that',\n",
       " 'keeping',\n",
       " 'these',\n",
       " 'tiny',\n",
       " 'differences',\n",
       " 'straight',\n",
       " 'requires',\n",
       " 'enormous',\n",
       " 'powers',\n",
       " 'of',\n",
       " 'concentration',\n",
       " 'and',\n",
       " 'memorization',\n",
       " '.',\n",
       " 'Readings',\n",
       " 'Geoffrey',\n",
       " 'Pullum',\n",
       " ',',\n",
       " '``',\n",
       " 'The',\n",
       " 'Awful',\n",
       " 'Chinese',\n",
       " 'Writing',\n",
       " 'System',\n",
       " \"''\",\n",
       " ',',\n",
       " 'Lingua',\n",
       " 'Franca',\n",
       " ',',\n",
       " 'The',\n",
       " 'Chronicle',\n",
       " 'of',\n",
       " 'Higher',\n",
       " 'Education',\n",
       " '(',\n",
       " '1/20/16',\n",
       " ')',\n",
       " '.',\n",
       " 'David',\n",
       " 'Moser',\n",
       " ',',\n",
       " '``',\n",
       " 'Why',\n",
       " 'Chinese',\n",
       " 'Is',\n",
       " 'So',\n",
       " 'Damn',\n",
       " 'Hard',\n",
       " \"''\",\n",
       " '(',\n",
       " 'html',\n",
       " ')',\n",
       " ',',\n",
       " 'pinyin.info',\n",
       " ',',\n",
       " 'readings',\n",
       " ';',\n",
       " '(',\n",
       " '简体字：为什么中文这么TM难？',\n",
       " ')',\n",
       " '(',\n",
       " '繁體字：為什麼中文這麼TM難？',\n",
       " ')',\n",
       " ';',\n",
       " 'from',\n",
       " 'Schriftfestschrift',\n",
       " ':',\n",
       " 'Essays',\n",
       " 'on',\n",
       " 'Writing',\n",
       " 'and',\n",
       " 'Language',\n",
       " 'in',\n",
       " 'Honor',\n",
       " 'of',\n",
       " 'John',\n",
       " 'DeFrancis',\n",
       " 'on',\n",
       " 'His',\n",
       " 'Eightieth',\n",
       " 'Birthday',\n",
       " '(',\n",
       " 'Sino-Platonic',\n",
       " 'Papers',\n",
       " '(',\n",
       " 'pdf',\n",
       " ')',\n",
       " 'No',\n",
       " '.',\n",
       " '27',\n",
       " ',',\n",
       " 'August',\n",
       " '1991',\n",
       " ')',\n",
       " ',',\n",
       " 'edited',\n",
       " 'by',\n",
       " 'Victor',\n",
       " 'H.',\n",
       " 'Mair',\n",
       " '.',\n",
       " 'Victor',\n",
       " 'H.',\n",
       " 'Mair',\n",
       " ',',\n",
       " '``',\n",
       " 'Aphantasia',\n",
       " '—',\n",
       " 'absence',\n",
       " 'of',\n",
       " 'the',\n",
       " 'mind',\n",
       " \"'s\",\n",
       " 'eye',\n",
       " \"''\",\n",
       " '(',\n",
       " 'Language',\n",
       " 'Log',\n",
       " ',',\n",
       " '3/24/17',\n",
       " ')',\n",
       " 'Other',\n",
       " 'Language',\n",
       " 'Log',\n",
       " 'posts',\n",
       " \"''\",\n",
       " 'Character',\n",
       " 'Amnesia',\n",
       " \"''\",\n",
       " '(',\n",
       " '7/22/10',\n",
       " ')',\n",
       " \"''\",\n",
       " 'Character',\n",
       " 'amnesia',\n",
       " 'revisited',\n",
       " \"''\",\n",
       " '(',\n",
       " '12/13/12',\n",
       " ')',\n",
       " \"''\",\n",
       " 'Spelling',\n",
       " 'bees',\n",
       " 'and',\n",
       " 'character',\n",
       " 'amnesia',\n",
       " \"''\",\n",
       " '(',\n",
       " '8/7/13',\n",
       " ')',\n",
       " \"''\",\n",
       " 'Character',\n",
       " 'amnesia',\n",
       " 'and',\n",
       " 'the',\n",
       " 'emergence',\n",
       " 'of',\n",
       " 'digraphia',\n",
       " \"''\",\n",
       " '(',\n",
       " '9/25/13',\n",
       " ')',\n",
       " \"''\",\n",
       " 'Dumpling',\n",
       " 'ingredients',\n",
       " 'and',\n",
       " 'character',\n",
       " 'amnesia',\n",
       " \"''\",\n",
       " '(',\n",
       " '10/18/14',\n",
       " ')',\n",
       " \"''\",\n",
       " 'Character',\n",
       " 'amnesia',\n",
       " 'in',\n",
       " '1793-1794',\n",
       " \"''\",\n",
       " '(',\n",
       " '4/24/14',\n",
       " ')',\n",
       " \"''\",\n",
       " 'Japanese',\n",
       " 'survey',\n",
       " 'on',\n",
       " 'forgetting',\n",
       " 'how',\n",
       " 'to',\n",
       " 'write',\n",
       " 'kanji',\n",
       " \"''\",\n",
       " '(',\n",
       " '9/24/12',\n",
       " ')',\n",
       " \"''\",\n",
       " 'Character',\n",
       " 'amnesia',\n",
       " 'redux',\n",
       " \"''\",\n",
       " '(',\n",
       " '4/22/16',\n",
       " ')',\n",
       " \"''\",\n",
       " 'The',\n",
       " 'naturalness',\n",
       " 'of',\n",
       " 'emerging',\n",
       " 'digraphia',\n",
       " \"''\",\n",
       " '(',\n",
       " '7/28/17',\n",
       " ')',\n",
       " \"''\",\n",
       " 'Learning',\n",
       " 'to',\n",
       " 'write',\n",
       " 'Chinese',\n",
       " 'characters',\n",
       " \"''\",\n",
       " '(',\n",
       " '7/29/17',\n",
       " ')',\n",
       " '[',\n",
       " 'Thanks',\n",
       " 'to',\n",
       " 'Zeyao',\n",
       " 'Wu',\n",
       " ']']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = BeautifulSoup(content).get_text()\n",
    "word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
