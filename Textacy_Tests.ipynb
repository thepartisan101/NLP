{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Textacy Tests.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOIj3ZoBJAOnUA1I87u/8xI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thepartisan101/NLP/blob/master/Textacy_Tests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuMNgWjtyWjq",
        "colab_type": "text"
      },
      "source": [
        "# Experiments with Textacy Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3d7jUwcyfFW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "2ee86a85-0eb7-4c68-9307-0649e7562d3b"
      },
      "source": [
        "!pip3 install spacy"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.38.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (46.1.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.6.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.4.5.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-HdPyuhy7G4",
        "colab_type": "text"
      },
      "source": [
        "## 1. Basics: Working with text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9m-iAR4zBSZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import textacy\n",
        "\n",
        "text = (\"Since the so-called \\\"statistical revolution\\\" in the late 1980s and mid 1990s, \"\n",
        "         \"much Natural Language Processing research has relied heavily on machine learning. \"\n",
        "        \"Formerly, many language-processing tasks typically involved the direct hand coding \"\n",
        "        \"of rules, which is not in general robust to natural language variation. \"\n",
        "        \"The machine-learning paradigm calls instead for using statistical inference \"\n",
        "        \"to automatically learn such rules through the analysis of large corpora \"\n",
        "        \"of typical real-world examples.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTOVZyD2zUDU",
        "colab_type": "text"
      },
      "source": [
        "#### Looking for keywords in context:\n",
        "*How a words or words are used in the text?*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZdQaaDrzPkn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "5852b689-e49b-42ca-f4ee-1d4d053b44ad"
      },
      "source": [
        "list(textacy.text_utils.KWIC(text, 'language', window_width=35))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 1980s and mid 1990s, much Natural  Language  Processing research has relied hea\n",
            "n machine learning. Formerly, many  language -processing tasks typically involve\n",
            "s not in general robust to natural  language  variation. The machine-learning pa\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n9ygoei0V1I",
        "colab_type": "text"
      },
      "source": [
        "#### Basic text preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxXKfJWYzoWZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from textacy import preprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8GaKo820doO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f8dd6cf-9ee0-4154-96f0-fccafa26e512"
      },
      "source": [
        "preprocessing.normalize_whitespace(preprocessing.remove_punctuation(text))[:80]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Since the so called statistical revolution in the late 1980s and mid 1990s much '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2BpuDaK0tTq",
        "colab_type": "text"
      },
      "source": [
        "## Making a Doc for processing\n",
        "##### Textacy includes automated language detection to apply rigth pipelines to text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vrj_nGTF0n0i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "b693c5d1-47e3-4155-ebd0-cc6bcb1d9e13"
      },
      "source": [
        "doc = textacy.make_spacy_doc(text)\n",
        "doc._.preview"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 66.7M/66.7M [00:00<00:00, 73.1MB/s]\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator HashingVectorizer from version 0.22 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.22 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.22 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.22 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Doc(85 tokens: \"Since the so-called \"statistical revolution\" in...\")'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vd5fJaA41Vtr",
        "colab_type": "text"
      },
      "source": [
        "#### Customizing pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01BwyiVa1J_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "en = textacy.load_spacy_lang(\"en_core_web_sm\", disable=(\"parser\",))\n",
        "doc = textacy.make_spacy_doc(text, lang=en)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmT4VYwf1kWM",
        "colab_type": "text"
      },
      "source": [
        "#### Keeping text metadata (author, URL, date) during processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1W7ZHSyx1fgk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ba0818f-e154-471e-f897-da853fe490e9"
      },
      "source": [
        "metadata = {\n",
        "    \"title\": \"Natural-language processing\",\n",
        "    \"url\": \"https://en.wikipedia.org/wiki/Natural-language_processing\",\n",
        "    \"source\": \"wikipedia\",\n",
        "}\n",
        "doc = textacy.make_spacy_doc((text, metadata))\n",
        "doc._.meta[\"title\"]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Natural-language processing'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbNsPnpz2NhC",
        "colab_type": "text"
      },
      "source": [
        "## Analyzing a Doc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmjXj8kA2Akp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "f7ddfa81-e151-480e-ed78-c6d738d3a427"
      },
      "source": [
        "list(textacy.extract.ngrams(\n",
        "    doc, 3, filter_stops=True, filter_punct=True, filter_nums=False\n",
        "))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1980s and mid,\n",
              " Natural Language Processing,\n",
              " Language Processing research,\n",
              " research has relied,\n",
              " heavily on machine,\n",
              " processing tasks typically,\n",
              " tasks typically involved,\n",
              " involved the direct,\n",
              " direct hand coding,\n",
              " coding of rules,\n",
              " robust to natural,\n",
              " natural language variation,\n",
              " learning paradigm calls,\n",
              " paradigm calls instead,\n",
              " inference to automatically,\n",
              " learn such rules,\n",
              " analysis of large,\n",
              " corpora of typical]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFvAL5rW2dEn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2dd00434-0d2c-48da-a522-cf98cbe5767c"
      },
      "source": [
        "list(textacy.extract.ngrams(doc, 2, min_freq=2))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Natural Language, natural language]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ausIWaAI2l7q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5102da62-f56e-43ef-f939-a4da21e5a9fc"
      },
      "source": [
        "list(textacy.extract.entities(doc, drop_determiners=True))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[late 1980s, mid 1990s, Natural Language Processing]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-jpgy6R2vyq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "78bb748f-41d9-4566-f9b3-40f5a48a5c4c"
      },
      "source": [
        "pattern = textacy.constants.POS_REGEX_PATTERNS[\"en\"][\"NP\"]\n",
        "pattern"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<DET>? <NUM>* (<ADJ> <PUNCT>? <CONJ>?)* (<NOUN>|<PROPN> <PART>?)+'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODpqC6QH232d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "6e7544b1-9956-49d4-bfc8-028a5c605e02"
      },
      "source": [
        "list(textacy.extract.pos_regex_matches(doc, pattern))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/textacy/extract.py:332: DeprecationWarning: `pos_regex_matches()` has been deprecated! for similar but more powerful and performant functionality, use `textacy.extract.matches()` instead.\n",
            "  action=\"once\",\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[statistical revolution,\n",
              " the late 1980s,\n",
              " mid 1990s,\n",
              " much Natural Language Processing research,\n",
              " machine learning,\n",
              " many language,\n",
              " processing tasks,\n",
              " the direct hand coding,\n",
              " rules,\n",
              " natural language variation,\n",
              " The machine,\n",
              " paradigm,\n",
              " statistical inference,\n",
              " such rules,\n",
              " the analysis,\n",
              " large corpora,\n",
              " typical real-world examples]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArOznCCj3LO8",
        "colab_type": "text"
      },
      "source": [
        "####  Identify key terms in a document by a number of algorithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3Selcs43NgR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "18bb40fe-1146-4313-81f7-45e00128a92e"
      },
      "source": [
        "import textacy.ke\n",
        "textacy.ke.textrank(doc, normalize='lemma', topn=10)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Natural Language Processing research', 0.059959246697826624),\n",
              " ('natural language variation', 0.04488350959275309),\n",
              " ('direct hand coding', 0.037736661821063354),\n",
              " ('statistical inference', 0.03432557996664981),\n",
              " ('statistical revolution', 0.034007535820683756),\n",
              " ('machine learning', 0.03305919655573349),\n",
              " ('mid 1990', 0.026993994406706995),\n",
              " ('late 1980', 0.026499549123496648),\n",
              " ('processing task', 0.0256684200517989),\n",
              " ('general robust', 0.024835834233545625)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7d0SDC73daZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "d8ae061d-83a3-4614-c118-116c20fcf0a5"
      },
      "source": [
        "textacy.ke.sgrank(doc, ngrams=(1, 2, 3, 4), normalize=\"lower\", topn=0.1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('natural language processing research', 0.3127324263926516),\n",
              " ('direct hand coding', 0.09689526575072321),\n",
              " ('natural language variation', 0.09379267126456722),\n",
              " ('mid 1990s', 0.051042393931910755),\n",
              " ('processing tasks', 0.04879465955786855)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8k4rreus3peR",
        "colab_type": "text"
      },
      "source": [
        "#### Compute basic counts and various readability statistics:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd9eGMCm3lmb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3665f25a-3343-4db9-8a20-c13fc34bdbb3"
      },
      "source": [
        "ts = textacy.TextStats(doc)\n",
        "ts.n_unique_words"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "57"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnzqMSOJ3z-E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "bcde869b-f8cc-4bb0-d8df-b3e122a4912a"
      },
      "source": [
        "ts.basic_counts"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_chars': 414,\n",
              " 'n_long_words': 30,\n",
              " 'n_monosyllable_words': 38,\n",
              " 'n_polysyllable_words': 19,\n",
              " 'n_sents': 3,\n",
              " 'n_syllables': 134,\n",
              " 'n_unique_words': 57,\n",
              " 'n_words': 73}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlZulXIF33EZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "639e7161-0788-4a08-eb12-6a2104938972"
      },
      "source": [
        "ts.flesch_kincaid_grade_level"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15.56027397260274"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_fa1QBc38Hc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "028dd81c-6100-4d1f-efb6-6b4dc9aa3170"
      },
      "source": [
        "ts.readability_stats"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'automated_readability_index': 17.448173515981736,\n",
              " 'coleman_liau_index': 16.32928468493151,\n",
              " 'flesch_kincaid_grade_level': 15.56027397260274,\n",
              " 'flesch_reading_ease': 26.84351598173518,\n",
              " 'gulpease_index': 44.61643835616438,\n",
              " 'gunning_fog_index': 20.144292237442922,\n",
              " 'lix': 65.42922374429223,\n",
              " 'smog_index': 17.5058628484301,\n",
              " 'wiener_sachtextformel': 11.857779908675797}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcEGOzDe3-Kz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "d46c4c63-e1df-4c2b-c9ce-9415bd53f783"
      },
      "source": [
        "bot = doc._.to_bag_of_terms(\n",
        "    ngrams=(1, 2, 3), entities=True, weighting='count',\n",
        "    as_strings=True\n",
        ")\n",
        "sorted(bot.items(), key=lambda x: x[1], reverse=True)[:15]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('call', 2),\n",
              " ('statistical', 2),\n",
              " ('machine', 2),\n",
              " ('language', 2),\n",
              " ('rule', 2),\n",
              " ('learn', 2),\n",
              " ('revolution', 1),\n",
              " ('late', 1),\n",
              " ('1980', 1),\n",
              " ('mid', 1),\n",
              " ('1990', 1),\n",
              " ('Natural', 1),\n",
              " ('Language', 1),\n",
              " ('Processing', 1),\n",
              " ('research', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEVh0jXT46kK",
        "colab_type": "text"
      },
      "source": [
        "## Working with Many Texts\n",
        "Textacy makes it easy to efficiently stream text and (text, metadata) pairs from disk, regardless of the format or compression of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pFA5IuO4gXi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "16f5a68d-d34b-4292-a071-8bed1ae617dc"
      },
      "source": [
        "!wget 'https://github.com/bdewilde/textacy-data/releases/download/capitol_words_py3_v1.0/capitol-words-py3.json.gz'"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-30 21:03:09--  https://github.com/bdewilde/textacy-data/releases/download/capitol_words_py3_v1.0/capitol-words-py3.json.gz\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/112271207/fdec3610-d3b7-11e7-817c-694c51f29888?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200430%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200430T210309Z&X-Amz-Expires=300&X-Amz-Signature=250cee7c6d7100502ae21613427538c0223c2dfe94976da7f8635a35fb942d75&X-Amz-SignedHeaders=host&actor_id=0&repo_id=112271207&response-content-disposition=attachment%3B%20filename%3Dcapitol-words-py3.json.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2020-04-30 21:03:09--  https://github-production-release-asset-2e65be.s3.amazonaws.com/112271207/fdec3610-d3b7-11e7-817c-694c51f29888?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200430%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200430T210309Z&X-Amz-Expires=300&X-Amz-Signature=250cee7c6d7100502ae21613427538c0223c2dfe94976da7f8635a35fb942d75&X-Amz-SignedHeaders=host&actor_id=0&repo_id=112271207&response-content-disposition=attachment%3B%20filename%3Dcapitol-words-py3.json.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.17.200\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.17.200|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11901699 (11M) [application/octet-stream]\n",
            "Saving to: ‘capitol-words-py3.json.gz’\n",
            "\n",
            "capitol-words-py3.j 100%[===================>]  11.35M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-04-30 21:03:09 (80.2 MB/s) - ‘capitol-words-py3.json.gz’ saved [11901699/11901699]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4ZfkCwn5nmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "records = textacy.io.read_json(\n",
        "    'capitol-words-py3.json.gz',\n",
        "    mode='rt', lines=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_wF2c8-6grD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "87ee675e-7e69-460f-c8b3-cdca75386c03"
      },
      "source": [
        "for record in records:\n",
        "  doc = textacy.make_spacy_doc((record['text'], {\"title\": record[\"title\"]}))\n",
        "  print(doc._.preview)\n",
        "  print('meta:', doc._.meta)\n",
        "  break"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Doc(159 tokens: \"Mr. Speaker, 480,000 Federal employees are work...\")\n",
            "meta: {'title': 'JOIN THE SENATE AND PASS A CONTINUING RESOLUTION'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JN4MqKO7Jmv",
        "colab_type": "text"
      },
      "source": [
        "#### convenient Dataset classes are already implemented in textacy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4gnh56b7MkX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "515f4ffb-5fe8-4365-c54d-c364e4a327ea"
      },
      "source": [
        "import textacy.datasets\n",
        "ds = textacy.datasets.CapitolWords()\n",
        "ds.download()\n",
        "records = ds.records(speaker_name={\"Barack Obama\", \"Joe Biden\"})\n",
        "next(records)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"Mr. President, a few days ago, the world watched as the seeds of democracy began to take root in Iraq. As a result of the sheer courage of the Iraqi people and the untold sacrifices of American soldiers, the success of the elections showed just how far people will go to achieve self-government and rule of law.\\nAs Americans, we can take enormous pride in the fact that this kind of courage has been inspired by our own struggle for freedom, by the tradition of democratic law secured by our forefathers and enshrined in our Constitution. It is a tradition that says all men are created equal under the law and that no one is above it.\\nThat is why even within the executive branch there is an office dedicated to enforcing the law of the land and applying it to people and to Presidents alike.\\nIn this sense, the Attorney General is not like the other Cabinet posts. Unlike the Secretary of State, who is the public face of the President's foreign policy, or the Secretary of Education, whose job it is to carry out the President's education policy, the Attorney General's job is not just to enforce the President's laws, it is to tell the President what the law is. The job is not simply to facilitate the President's power, it is to speak truth to that power as well.\\nThe job is to protect and defend the laws of freedoms for which so many have sacrificed so much.\\nThe President is not the Attorney General's client; the people are. And so the true test of an Attorney General nominee is whether that person is ready to put the Constitution of the people before the political agenda of the President. As such, I cannot approach this nomination for Attorney General the same way I approached that of Secretary of State Rice or Veterans Affairs Secretary Nicholson or any other Cabinet position. The standard is simply higher.\\nLike the previous speaker, Senator Dodd, I wanted to give Alberto Gonzales the benefit of the doubt when we began this process. His story is inspiring, especially for so many of us — like me — who shared in achieving the American dream. I have no question that as White House Counsel, he has served his President and his country to the best of his ability. But in my judgment, these positive qualities alone are not sufficient to warrant confirmation as the top law enforcement officer in the land.\\nI had hoped that during his hearings, Judge Gonzales would ease my concerns about some of the legal advice he gave to the President, and I had hoped he would prove that he has the ability to distance himself from his role as the President's lawyer so that he could perform his new role as the people's lawyer.\\nUnfortunately, rather than full explanations during these hearings, I heard equivocation. Rather than independence, I heard an unyielding insistence on protecting the President's prerogative.\\nI did not hear Judge Gonzales repudiate 2\\\\1/2\\\\ years of what appears to be official U.S. policy that has defined torture so narrowly that only organ failure and death would qualify, a policy that he himself appears to have helped develop and at least has condoned.\\nImagine that, if the entire world accepted the definition contained in the Department of Justice memos, we can only imagine what atrocities might befall our American POWs. How in the world, without such basic constraints, would we feel about sending our sons and daughters off to war? How, if we are willing to rationalize torture through legalisms and semantics, can we claim to our children and the children of the world that America is different and represents a higher moral standard?\\nThis policy is not just a moral failure, it is a violation of half a century of international law. Yet while Judge Gonzales's job was White House Counsel, he said nothing to that effect to the President of the United States. He did not show an ability to speak with responsible moral clarity then, and he has indicated that he still has no intention to speak such truths now.\\nDuring his recent testimony, he refused to refute a conclusion in the torture memo which stated that the President has the power to override our laws when acting as Commander in Chief. Think about this. The Nation's top law enforcement officer telling its most powerful citizen that if the situation warrants, the President can break the law from time to time.\\nThe truth is, Mr. Gonzales has raised serious doubts about whether, given the choice between the Constitution and the President's political agenda, he would put our Constitution first. And that is why I simply cannot support his nomination for Attorney General.\\nI understand that Judge Gonzales will most likely be confirmed, and I look forward to working with him in that new role. But I also hope that once in office, he will take the lessons of this debate to heart.\\nBefore serving in this distinguished body, I had the privilege of teaching law for 10 years at the University of Chicago. Among the brilliant minds to leave that institution for Government service was a former dean of the law school named Edward Levi, a man of impeccable integrity who was committed to the rule of law before politics.\\nEdward Levi was chosen by President Ford to serve as Attorney General in the wake of Watergate. The President courageously chose to appoint him not because Dean Levi was a yes man, not because he was a loyal political soldier, but so that he could restore the public's confidence in a badly damaged Justice Department, so that he could restore the public's trust and the ability of our leaders to follow the law.\\nWhile he has raised serious doubts about his ability to follow this example, Judge Gonzales can still choose to restore our trust. He can still choose to put the Constitution first. I hope for our country's sake that he will, and part of the reason I am speaking in this Chamber today is to suggest three steps that he can take upon assuming his role that would help restore that trust.\\nFirst, he can immediately repudiate the terror memos in question and ensure that the Department of Defense is not using any of its recommendations to craft interrogation policies.\\nSecond, Judge Gonzales can restore the credibility of his former position as legal counsel by appointing an independent-minded, universally respected lawyer to the post.\\nAnd third, he can provide this Congress regular detailed reports on his efforts to live up to the President's stated zero tolerance policy with respect to torture.\\nToday we are engaged in a deadly global struggle for those who would intimidate, torture, and murder people for exercising the most basic freedoms. If we are to win this struggle and spread those freedoms, we must keep our own moral compass pointed in a true direction. The Attorney General is one figure charged with doing this, but to do it well, he must demonstrate a higher loyalty than just to the President. He must demonstrate a loyalty to the ideals that inspire a nation and, hopefully, the world.\\nI thank the Chair.\",\n",
              " {'chamber': 'Senate',\n",
              "  'congress': 109,\n",
              "  'date': '2005-02-03',\n",
              "  'speaker_name': 'Barack Obama',\n",
              "  'speaker_party': 'D',\n",
              "  'title': 'EXECUTIVE SESSION'})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6E-ikMM71i2",
        "colab_type": "text"
      },
      "source": [
        "## Make a Corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rI10mSEt7m0_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = textacy.Corpus('en', data=records)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0tMkn587-85",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6f120fe9-f604-44b1-d8f7-dc33ebffc1eb"
      },
      "source": [
        "textacy.Corpus(\n",
        "      textacy.load_spacy_lang(\"en_core_web_sm\", disable=(\"parser\", \"tagger\")),\n",
        "        data=ds.texts(speaker_party=\"R\", chamber=\"House\", limit=100))\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<textacy.corpus.Corpus at 0x7efc204bf320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2KkXgfx81L6",
        "colab_type": "text"
      },
      "source": [
        "##### You can use basic indexing as well as flexible boolean queries to select documents in a corpus:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Yv72pIZ8ZrB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a1a9900d-2546-42e9-d160-ba63a52e7b28"
      },
      "source": [
        "corpus[100]._.preview"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Doc(1578 tokens: \"Mr. President, in the immediate aftermath of Hu...\")'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sB6eGVa87_7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "ae3def4d-fe0b-41a1-c919-0fbd375bc962"
      },
      "source": [
        "[doc._.preview for doc in corpus[10:15]]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Doc(15380 tokens: \"Mr. President, I am pleased to join as a cospon...\")',\n",
              " 'Doc(296 tokens: \"Today I wish to commend Congressman Bobby Rush ...\")',\n",
              " 'Doc(3479 tokens: \" There being no objection, the bill was ordered...\")',\n",
              " 'Doc(17 tokens: \"Mr. President, I ask unanimous consent that the...\")',\n",
              " 'Doc(875 tokens: \"Mr. President, I rise today to urge my colleagu...\")']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZruf2pu9AfU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d43f701b-2dcd-4cb9-8737-5ef1829b6546"
      },
      "source": [
        "obama_docs = list(corpus.get(lambda doc: doc._.meta[\"speaker_name\"] == \"Barack Obama\"))\n",
        "len(obama_docs)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "410"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_hNSb9I9Tjg",
        "colab_type": "text"
      },
      "source": [
        "## Analyze a Corpus\n",
        "Basic stats are computed on the fly as documents are added (or removed) from a corpus:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSU1yeam9GBj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7a1062c-4917-4f19-9468-92290a94c0a7"
      },
      "source": [
        "corpus.n_docs, corpus.n_sents, corpus.n_tokens"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(411, 10914, 270636)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsFRKEha9lCw",
        "colab_type": "text"
      },
      "source": [
        "Transform a corpus into a document-term matrix, with flexible tokenization, weighting, and filtering of terms:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7z-l6i79hv-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "30923e3c-3da9-4d7d-f3ee-62b27100bd0b"
      },
      "source": [
        "import textacy\n",
        "import textacy.vsm\n",
        "vectorizer = textacy.Vectorizer(\n",
        "    tf_type=\"linear\", apply_idf=True, idf_type=\"smooth\", norm=\"l2\",\n",
        "    min_df=2, max_df=0.95)\n",
        "doc_term_matrix = vectorizer.fit_transform(\n",
        "    (doc._.to_terms_list(ngrams=1, entities=True, as_strings=True)\n",
        "    for doc in corpus))\n",
        "print(rpr(doc_term_matrix))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-4cc75880e8b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtextacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtextacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvsm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m vectorizer = textacy.Vectorizer(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtf_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"linear\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_idf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midf_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"smooth\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"l2\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     min_df=2, max_df=0.95)\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'textacy' has no attribute 'Vectorizer'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETW-fzrI9azG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "308cfe1f-2868-497e-d8e5-c176d96326a7"
      },
      "source": [
        "dir(textacy)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Corpus',\n",
              " 'DEFAULT_DATA_DIR',\n",
              " 'TextStats',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '__version__',\n",
              " 'about',\n",
              " 'cache',\n",
              " 'constants',\n",
              " 'corpus',\n",
              " 'datasets',\n",
              " 'extract',\n",
              " 'io',\n",
              " 'ke',\n",
              " 'lang_utils',\n",
              " 'load_spacy_lang',\n",
              " 'logger',\n",
              " 'logging',\n",
              " 'make_spacy_doc',\n",
              " 'network',\n",
              " 'preprocessing',\n",
              " 'set_doc_extensions',\n",
              " 'similarity',\n",
              " 'spacier',\n",
              " 'text_stats',\n",
              " 'text_utils',\n",
              " 'utils',\n",
              " 'vsm']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztYbr8AB_G5c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "745af1e2-682e-4653-ac11-6b0051acd95d"
      },
      "source": [
        "textacy.Vectorizer"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-60485ad0cd96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtextacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'textacy' has no attribute 'Vectorizer'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT243Epa_UE5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}